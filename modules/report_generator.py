"""
æ€§èƒ½æŠ¥å‘Šç”Ÿæˆæ¨¡å—

è´Ÿè´£åˆ†ææ€§èƒ½æ•°æ®å¹¶ç”Ÿæˆæ ¼å¼åŒ–çš„æŠ¥å‘Šï¼ŒåŒ…æ‹¬æ€§èƒ½è¯„åˆ†å’Œä¼˜åŒ–å»ºè®®
"""

import json
import logging
from typing import Dict, Any, List, Tuple
from datetime import datetime

class ReportGenerator:
    """æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
        self.logger = logging.getLogger(__name__)
        
        # æ€§èƒ½é˜ˆå€¼é…ç½®ï¼ˆæ¯«ç§’ï¼‰
        self.thresholds = {
            "fcp": {"good": 1800, "poor": 3000},      # First Contentful Paint
            "lcp": {"good": 2500, "poor": 4000},      # Largest Contentful Paint
            "ttfb": {"good": 200, "poor": 600},       # Time to First Byte
            "dom_ready": {"good": 2000, "poor": 4000}, # DOM Ready
            "page_load": {"good": 3000, "poor": 5000}  # Page Load
        }
    
    def generate_report(self, performance_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
        
        Args:
            performance_data: æ€§èƒ½æ•°æ®
            
        Returns:
            æ ¼å¼åŒ–çš„æ€§èƒ½æŠ¥å‘Š
        """
        if "error" in performance_data:
            return self._generate_error_report(performance_data)
        
        try:
            # æå–å…³é”®æŒ‡æ ‡
            key_metrics = self._extract_key_metrics(performance_data)
            
            # è®¡ç®—æ€§èƒ½è¯„åˆ†
            scores = self._calculate_scores(key_metrics)
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            recommendations = self._generate_recommendations(key_metrics, scores)
            
            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            report = {
                "url": performance_data.get("url", "Unknown"),
                "timestamp": performance_data.get("timestamp", datetime.now().timestamp()),
                "test_date": datetime.fromtimestamp(
                    performance_data.get("timestamp", datetime.now().timestamp())
                ).strftime("%Y-%m-%d %H:%M:%S"),
                "load_time": performance_data.get("load_time", 0),
                "key_metrics": key_metrics,
                "scores": scores,
                "overall_score": self._calculate_overall_score(scores),
                "recommendations": recommendations,
                "raw_data": performance_data
            }
            
            self.logger.info(f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š: {report['url']}")
            return report
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return self._generate_error_report({"url": performance_data.get("url"), "error": str(e)})
    
    def _extract_key_metrics(self, data: Dict[str, Any]) -> Dict[str, float]:
        """æå–å…³é”®æ€§èƒ½æŒ‡æ ‡"""
        metrics = {}
        
        # å¤„ç†æ–°çš„æ’ä»¶åŒ–æ•°æ®ç»“æ„
        if "performance_data" in data:
            # æ–°çš„æ’ä»¶åŒ–æ¶æ„æ•°æ®ç»“æ„
            performance_data = data["performance_data"]
            
            # ä»æ”¶é›†å™¨æ•°æ®ä¸­æå–æŒ‡æ ‡
            if "data" in performance_data:
                collector_data = performance_data["data"]
                
                # ä» PaintCollector ä¸­æå–ç»˜åˆ¶æŒ‡æ ‡
                if "PaintCollector" in collector_data:
                    paint_data = collector_data["PaintCollector"].get("data", {})
                    if "first-contentful-paint" in paint_data:
                        metrics["fcp"] = paint_data["first-contentful-paint"]
                    if "largest-contentful-paint" in paint_data:
                        metrics["lcp"] = paint_data["largest-contentful-paint"]
                
                # ä» NavigationCollector ä¸­æå–å¯¼èˆªæ—¶åº
                if "NavigationCollector" in collector_data:
                    nav_data = collector_data["NavigationCollector"].get("data", {})
                    if nav_data:
                        metrics["ttfb"] = nav_data.get("ttfb", 0)
                        metrics["dom_ready"] = nav_data.get("domReady", 0)
                        metrics["page_load"] = nav_data.get("pageLoad", 0)
                        metrics["dns_lookup"] = nav_data.get("dnsLookup", 0)
                        metrics["tcp_connect"] = nav_data.get("tcpConnect", 0)
                
                # ä» PerformanceCollector ä¸­æå–æ€§èƒ½æŒ‡æ ‡
                if "PerformanceMetricsCollector" in collector_data:
                    perf_data = collector_data["PerformanceMetricsCollector"].get("data", {})
                    for key, value in perf_data.items():
                        if key not in metrics and isinstance(value, (int, float)):
                            metrics[key] = value
                
                # ä» MemoryCollector ä¸­æå–å†…å­˜æŒ‡æ ‡
                if "MemoryCollector" in collector_data:
                    memory_data = collector_data["MemoryCollector"].get("data", {})
                    if memory_data:
                        metrics["memory_used"] = memory_data.get("usedJSHeapSize", 0)
                        metrics["memory_total"] = memory_data.get("totalJSHeapSize", 0)
                        metrics["memory_limit"] = memory_data.get("jsHeapSizeLimit", 0)
        
        # å…¼å®¹æ—§çš„æ•°æ®ç»“æ„æ ¼å¼
        else:
            # ä»ç»˜åˆ¶æŒ‡æ ‡ä¸­æå–
            paint_metrics = data.get("paint_metrics", {})
            if "first-contentful-paint" in paint_metrics:
                metrics["fcp"] = paint_metrics["first-contentful-paint"]
            if "largest-contentful-paint" in paint_metrics:
                metrics["lcp"] = paint_metrics["largest-contentful-paint"]
            
            # ä»å¯¼èˆªæ—¶åºä¸­æå–
            nav_timing = data.get("navigation_timing", {})
            if nav_timing:
                metrics["ttfb"] = nav_timing.get("ttfb", 0)
                metrics["dom_ready"] = nav_timing.get("domReady", 0)
                metrics["page_load"] = nav_timing.get("pageLoad", 0)
                metrics["dns_lookup"] = nav_timing.get("dnsLookup", 0)
                metrics["tcp_connect"] = nav_timing.get("tcpConnect", 0)
            
            # ä»æ€§èƒ½æŒ‡æ ‡ä¸­è¡¥å……
            perf_metrics = data.get("performance_metrics", {})
            for key, value in perf_metrics.items():
                if key not in metrics and isinstance(value, (int, float)):
                    metrics[key] = value
        
        self.logger.debug(f"æå–åˆ° {len(metrics)} ä¸ªå…³é”®æŒ‡æ ‡: {list(metrics.keys())}")
        return metrics
    
    def _calculate_scores(self, metrics: Dict[str, float]) -> Dict[str, Dict[str, Any]]:
        """è®¡ç®—å„é¡¹æ€§èƒ½è¯„åˆ†"""
        scores = {}
        
        for metric_name, value in metrics.items():
            if metric_name in self.thresholds:
                threshold = self.thresholds[metric_name]
                score_info = self._calculate_metric_score(value, threshold)
                scores[metric_name] = score_info
        
        return scores
    
    def _calculate_metric_score(self, value: float, threshold: Dict[str, float]) -> Dict[str, Any]:
        """è®¡ç®—å•ä¸ªæŒ‡æ ‡çš„è¯„åˆ†"""
        good_threshold = threshold["good"]
        poor_threshold = threshold["poor"]
        
        if value <= good_threshold:
            rating = "good"
            score = 90 + (good_threshold - value) / good_threshold * 10
        elif value <= poor_threshold:
            rating = "needs_improvement"
            score = 50 + (poor_threshold - value) / (poor_threshold - good_threshold) * 40
        else:
            rating = "poor"
            score = max(0, 50 - (value - poor_threshold) / poor_threshold * 50)
        
        return {
            "value": value,
            "score": min(100, max(0, score)),
            "rating": rating,
            "threshold_good": good_threshold,
            "threshold_poor": poor_threshold
        }
    
    def _calculate_overall_score(self, scores: Dict[str, Dict[str, Any]]) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        if not scores:
            return 0.0
        
        # æƒé‡é…ç½®
        weights = {
            "fcp": 0.25,
            "lcp": 0.25,
            "ttfb": 0.20,
            "dom_ready": 0.15,
            "page_load": 0.15
        }
        
        total_score = 0.0
        total_weight = 0.0
        
        for metric_name, score_info in scores.items():
            weight = weights.get(metric_name, 0.1)
            total_score += score_info["score"] * weight
            total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def _generate_recommendations(self, metrics: Dict[str, float], 
                                scores: Dict[str, Dict[str, Any]]) -> List[Dict[str, str]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # FCP ä¼˜åŒ–å»ºè®®
        if "fcp" in scores and scores["fcp"]["rating"] != "good":
            recommendations.append({
                "category": "First Contentful Paint",
                "priority": "high" if scores["fcp"]["rating"] == "poor" else "medium",
                "issue": f"é¦–æ¬¡å†…å®¹ç»˜åˆ¶æ—¶é—´ä¸º {scores['fcp']['value']:.0f}msï¼Œéœ€è¦ä¼˜åŒ–",
                "suggestions": [
                    "ä¼˜åŒ–å…³é”®æ¸²æŸ“è·¯å¾„ï¼Œå‡å°‘é˜»å¡èµ„æº",
                    "å‹ç¼©å’Œä¼˜åŒ– CSSã€JavaScript æ–‡ä»¶",
                    "ä½¿ç”¨ CDN åŠ é€Ÿé™æ€èµ„æºåŠ è½½",
                    "å¯ç”¨æœåŠ¡å™¨ç«¯æ¸²æŸ“æˆ–é¢„æ¸²æŸ“"
                ]
            })
        
        # LCP ä¼˜åŒ–å»ºè®®
        if "lcp" in scores and scores["lcp"]["rating"] != "good":
            recommendations.append({
                "category": "Largest Contentful Paint",
                "priority": "high" if scores["lcp"]["rating"] == "poor" else "medium",
                "issue": f"æœ€å¤§å†…å®¹ç»˜åˆ¶æ—¶é—´ä¸º {scores['lcp']['value']:.0f}msï¼Œéœ€è¦ä¼˜åŒ–",
                "suggestions": [
                    "ä¼˜åŒ–å›¾ç‰‡åŠ è½½ï¼Œä½¿ç”¨é€‚å½“çš„æ ¼å¼å’Œå°ºå¯¸",
                    "é¢„åŠ è½½å…³é”®èµ„æº",
                    "ä¼˜åŒ–æœåŠ¡å™¨å“åº”æ—¶é—´",
                    "é¿å…å¤§å‹å¸ƒå±€åç§»"
                ]
            })
        
        # TTFB ä¼˜åŒ–å»ºè®®
        if "ttfb" in scores and scores["ttfb"]["rating"] != "good":
            recommendations.append({
                "category": "Time to First Byte",
                "priority": "high",
                "issue": f"é¦–å­—èŠ‚æ—¶é—´ä¸º {scores['ttfb']['value']:.0f}msï¼ŒæœåŠ¡å™¨å“åº”è¾ƒæ…¢",
                "suggestions": [
                    "ä¼˜åŒ–æœåŠ¡å™¨æ€§èƒ½å’Œæ•°æ®åº“æŸ¥è¯¢",
                    "ä½¿ç”¨ç¼“å­˜ç­–ç•¥",
                    "é€‰æ‹©æ›´å¥½çš„æœåŠ¡å™¨æˆ–æ‰˜ç®¡æœåŠ¡",
                    "ä¼˜åŒ–ç½‘ç»œè¿æ¥"
                ]
            })
        
        # DOM Ready ä¼˜åŒ–å»ºè®®
        if "dom_ready" in scores and scores["dom_ready"]["rating"] != "good":
            recommendations.append({
                "category": "DOM Ready Time",
                "priority": "medium",
                "issue": f"DOM å‡†å¤‡æ—¶é—´ä¸º {scores['dom_ready']['value']:.0f}msï¼Œéœ€è¦ä¼˜åŒ–",
                "suggestions": [
                    "å‡å°‘ DOM å¤æ‚åº¦",
                    "å¼‚æ­¥åŠ è½½éå…³é”® JavaScript",
                    "ä¼˜åŒ– CSS åŠ è½½é¡ºåº",
                    "ä½¿ç”¨ä»£ç åˆ†å‰²æŠ€æœ¯"
                ]
            })
        
        # Page Load ä¼˜åŒ–å»ºè®®
        if "page_load" in scores and scores["page_load"]["rating"] != "good":
            recommendations.append({
                "category": "Page Load Time",
                "priority": "medium",
                "issue": f"é¡µé¢åŠ è½½æ—¶é—´ä¸º {scores['page_load']['value']:.0f}msï¼Œæ•´ä½“æ€§èƒ½éœ€è¦æå‡",
                "suggestions": [
                    "å‹ç¼©å’Œä¼˜åŒ–æ‰€æœ‰èµ„æº",
                    "å¯ç”¨ Gzip å‹ç¼©",
                    "å‡å°‘ HTTP è¯·æ±‚æ•°é‡",
                    "ä½¿ç”¨æµè§ˆå™¨ç¼“å­˜"
                ]
            })
        
        # ç½‘ç»œç›¸å…³å»ºè®®
        dns_time = metrics.get("dns_lookup", 0)
        if dns_time > 100:
            recommendations.append({
                "category": "DNS Lookup",
                "priority": "low",
                "issue": f"DNS æŸ¥è¯¢æ—¶é—´ä¸º {dns_time:.0f}msï¼Œå¯ä»¥ä¼˜åŒ–",
                "suggestions": [
                    "ä½¿ç”¨æ›´å¿«çš„ DNS æœåŠ¡å™¨",
                    "å¯ç”¨ DNS é¢„è§£æ",
                    "å‡å°‘å¤–éƒ¨åŸŸåå¼•ç”¨"
                ]
            })
        
        tcp_time = metrics.get("tcp_connect", 0)
        if tcp_time > 100:
            recommendations.append({
                "category": "TCP Connection",
                "priority": "low",
                "issue": f"TCP è¿æ¥æ—¶é—´ä¸º {tcp_time:.0f}msï¼Œå¯ä»¥ä¼˜åŒ–",
                "suggestions": [
                    "å¯ç”¨ HTTP/2 æˆ– HTTP/3",
                    "ä½¿ç”¨ CDN å‡å°‘è¿æ¥è·ç¦»",
                    "å¯ç”¨ Keep-Alive è¿æ¥"
                ]
            })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"high": 0, "medium": 1, "low": 2}
        recommendations.sort(key=lambda x: priority_order.get(x["priority"], 3))
        
        return recommendations
    
    def _generate_error_report(self, error_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
        return {
            "url": error_data.get("url", "Unknown"),
            "timestamp": datetime.now().timestamp(),
            "test_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "error": error_data.get("error", "Unknown error"),
            "success": False
        }
    
    def format_report_text(self, report: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æŠ¥å‘Šä¸ºæ–‡æœ¬æ ¼å¼"""
        if not report.get("success", True):
            return f"""
æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
{'='*50}

URL: {report['url']}
æµ‹è¯•æ—¶é—´: {report['test_date']}
çŠ¶æ€: æµ‹è¯•å¤±è´¥
é”™è¯¯: {report.get('error', 'Unknown error')}
"""
        
        text = f"""
æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
{'='*50}

URL: {report['url']}
æµ‹è¯•æ—¶é—´: {report['test_date']}
æ€»ä½“è¯„åˆ†: {report['overall_score']:.1f}/100

å…³é”®æŒ‡æ ‡:
{'-'*30}
"""
        
        # æ·»åŠ å…³é”®æŒ‡æ ‡
        for metric_name, score_info in report.get("scores", {}).items():
            rating_emoji = {"good": "âœ…", "needs_improvement": "âš ï¸", "poor": "âŒ"}
            emoji = rating_emoji.get(score_info["rating"], "â“")
            
            text += f"{emoji} {metric_name.upper()}: {score_info['value']:.0f}ms (è¯„åˆ†: {score_info['score']:.1f})\n"
        
        # æ·»åŠ ä¼˜åŒ–å»ºè®®
        recommendations = report.get("recommendations", [])
        if recommendations:
            text += f"\nä¼˜åŒ–å»ºè®®:\n{'-'*30}\n"
            for i, rec in enumerate(recommendations, 1):
                priority_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                emoji = priority_emoji.get(rec["priority"], "âšª")
                
                text += f"\n{i}. {emoji} {rec['category']}\n"
                text += f"   é—®é¢˜: {rec['issue']}\n"
                text += f"   å»ºè®®:\n"
                for suggestion in rec["suggestions"]:
                    text += f"   â€¢ {suggestion}\n"
        
        return text
    
    def save_report(self, report: Dict[str, Any], filepath: str, format_type: str = "json"):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            report: æŠ¥å‘Šæ•°æ®
            filepath: ä¿å­˜è·¯å¾„
            format_type: æ ¼å¼ç±»å‹ ('json' æˆ– 'txt')
        """
        try:
            if format_type.lower() == "json":
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
            else:
                text_report = self.format_report_text(report)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(text_report)
            
            self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
